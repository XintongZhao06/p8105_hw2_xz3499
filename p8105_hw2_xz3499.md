p8105_hw2_xz3499
================
Xintong Zhao
2025-09-25

## Problem 1

### 1. Load required libraries

``` r
library(tidyverse)
library(lubridate)
```

### 2. Load the dataset

``` r
pols_month <- read_csv("fivethirtyeight_datasets/pols-month.csv")
snp <- read_csv("fivethirtyeight_datasets/snp.csv")
unemployment <- read_csv("fivethirtyeight_datasets/unemployment.csv")
```

### 3. Clean the data in pols-month.csv

``` r
#Quickly view the data
glimpse(pols_month)
```

    ## Rows: 822
    ## Columns: 9
    ## $ mon      <date> 1947-01-15, 1947-02-15, 1947-03-15, 1947-04-15, 1947-05-15, …
    ## $ prez_gop <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
    ## $ gov_gop  <dbl> 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 22, 22, 22, 2…
    ## $ sen_gop  <dbl> 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 53, 53, 53, 5…
    ## $ rep_gop  <dbl> 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 2…
    ## $ prez_dem <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…
    ## $ gov_dem  <dbl> 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 2…
    ## $ sen_dem  <dbl> 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 48, 48, 48, 4…
    ## $ rep_dem  <dbl> 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 1…

``` r
pols_clean <- pols_month %>% 
  separate(mon, 
           into = c("year","month","day"),
           sep = "-"
           ) %>% 
  mutate(
    month = as.numeric(month),
    month = month.name[month],
    year = as.numeric(year),
    day = as.numeric(day)
  ) %>% 
  mutate(president = ifelse(prez_gop == 1, "gop", "dem")) %>% 
  select(-prez_gop, -prez_dem, -day)

view(pols_clean)
```

### 4. Clean the data in snp.csv

``` r
#Quickly view the data
glimpse(snp)
```

    ## Rows: 787
    ## Columns: 2
    ## $ date  <chr> "7/1/15", "6/1/15", "5/1/15", "4/1/15", "3/2/15", "2/2/15", "1/2…
    ## $ close <dbl> 2079.65, 2063.11, 2107.39, 2085.51, 2067.89, 2104.50, 1994.99, 2…

``` r
snp_clean <-snp %>% 
  separate(date, 
           into = c("month","day","year"),
           sep = "/"
           ) %>% 
  mutate(
    month = as.numeric(month),
    month = month.name[month],
    year = as.numeric(year),
    year = ifelse(year < 50, 2000 + year, 1900 + year),
    day = as.numeric(day)
  ) %>% 
  select(year, month, close) %>% 
  arrange(year, month)
  
view(snp_clean)
```

### 5. Tidy the unemployment data

``` r
unemployment_clean <- unemployment %>% 
  pivot_longer(
    cols = Jan : Dec,
    names_to = "month",
    values_to = "unemployment_rate"
  ) %>% 
  mutate(
    month = case_when(
      month == "Jan" ~ "January",
      month == "Feb" ~ "February",
      month == "Mar" ~ "March",
      month == "Apr" ~ "April",
      month == "May" ~ "May",
      month == "Jun" ~ "June",
      month == "Jul" ~ "July",
      month == "Aug" ~ "August",
      month == "Sep" ~ "September",
      month == "Oct" ~ "October",
      month == "Nov" ~ "November",
      month == "Dec" ~ "December"
    )
  ) %>% 
  select(year = Year, month, unemployment_rate) %>% 
  arrange(year, month)

view(unemployment_clean)
```

### 6. Join the datasets

``` r
merged_data <- left_join(pols_clean, snp_clean, by = c("year","month"))
final_data <- left_join(merged_data, unemployment_clean, by= c("year","month"))

view(final_data)
```

### 7. Description

- The **“pols_clean”** dataset contains monthly data related to American
  politics, spanning from 1947 to 2015, with a total of 822 rows of
  observational data. It specifically includes the number of Democratic
  and Republican politicians (including governors, senators and
  representatives) at different times, as well as the party information
  of the president. The key variables include the number of Republican
  governors (`gov_gop`), the number of Republican senators (`sen_gop`),
  the number of Republican representatives (`rep_gop`), the number of
  Democratic governors (`gov_dem`), the number of Democratic senators
  (`sen_dem`), the number of Democratic representatives (`rep_dem`), and
  the presidential party (`president`).

- The **“snp_clean”** dataset contains monthly closing price data of the
  S&P index, spanning from 1950 to 2015, with a total of 787 rows of
  observational data. The key variable is the closing price (`close`).

- The **“unemployment_clean”** dataset contains monthly unemployment
  rate data in the United States, spanning from 1948 to 2015, with a
  total of 816 rows of observational data. The key variable is the
  unemployment rate (`unemployment_rate`).

- **“final_data”** contains all the information of the above three
  datasets, including 11 variables and 822 rows of observational data,
  spanning from 1947 to 2015. It provides a reference basis for
  analyzing the historical development of the United States from three
  dimensions: politics, economy, and employment. Due to the inconsistent
  time spans of various datasets, there are some missing values after
  merging.

## Problem 2

### 1. Load required libraries

``` r
library(readxl)
```

### 2. Read and clean the Mr. Trash Wheel sheet

``` r
#Specify the sheet in the Excel file and to omit non-data entries
mr_trash <- read_excel("202409 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", skip = 1, range = cell_cols("A:N")) %>% 
  #Use reasonable variable names
  janitor::clean_names() %>% 
  #Omit rows that do not include dumpster-specific data
  filter(!is.na(dumpster)) %>% 
  #Round the number of sports balls to the nearest integer and converts the result to an integer variable
  mutate(
    sports_balls = as.integer(round(sports_balls)),
    year = as.character(year)
    ) %>% 
  #Add an additional variable to keep track of which Trash Wheel is which
  mutate(trash_wheel = "Mr. Trash Wheel") %>% 
  select(trash_wheel,everything())

view(mr_trash)
```

### 3. Read and clean the Professor Trash Wheel sheet

``` r
professor_trash <- read_excel("202409 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", skip = 1) %>%
  janitor::clean_names() %>%
  filter(!is.na(dumpster)) %>%
  mutate(
    trash_wheel = "Professor Trash Wheel",
    year = as.character(year)
    ) %>% 
  select(trash_wheel,everything())

view(professor_trash)
```

### 4. Read and clean the Gwynnda Trash Wheel sheet

``` r
gwynnda_trash <- read_excel("202409 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1) %>%
  janitor::clean_names() %>%
  filter(!is.na(dumpster)) %>%
  mutate(
    trash_wheel = "Gwynnda Trash Wheel",
    year = as.character(year)
    ) %>% 
  select(trash_wheel,everything())

view(gwynnda_trash)
```

### 5. Combine these datasets to produce a single tidy dataset

``` r
combined_trash <- bind_rows(mr_trash, professor_trash, gwynnda_trash) %>%
  #Make sure the date format is consistent
  mutate(date = as.Date(date))

view(combined_trash)
```

### 6. Description

- The above three datasets record the garbage collection situations of
  three garbage collection boats (Mr. Trash Wheel, Professor Trash Wheel
  and Gwynnda) in the Inner Harbor of Baltimore. The merged dataset
  contains a total of 1033 observations, and each observation represents
  a trash can collection record. The key variables include the
  `trash_wheel` identification of the garbage collection vessel, the
  `dumpster` number, the collection `date`, the `weight_tons` weight of
  the garbage, and the `volume_cubic_yards` volume. Unit: cubic yards),
  quantities of various types of garbage (such as plastic bottles
  `plastic_bottles`, `polystyrene`, cigarettebutts `cigarette_butts`,
  glass bottles `glass_bottles`, plastic bags `plastic_bags`, packaging
  bags `wrappers`, etc.) And the number of households powered based on
  garbage weight calculation (`homes_powered`).

- According to the available data, the total weight of the garbage
  collected by Professor Trash Wheel was 246.74 tons. The total number
  of cigarette butts collected by Gwynnda in June 2022 was 1.812^{4}.

## Problem 3

### 1. Read and clean the zip dataset

``` r
zip <- read_csv("zillow_data/Zip Codes.csv") %>% 
  janitor::clean_names() 

view(zip)
```

### 2. Read and clean the zori dataset

``` r
#Create a borough mapping table
borough_mapping <- data.frame(
  county = c("New York", "Kings", "Queens", "Bronx", "Richmond"),
  borough = c("Manhattan", "Brooklyn", "Queens", "Bronx", "Staten Island")
)

zori <- read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") %>% 
  janitor::clean_names()

zillow_data <- zori %>% 
  rename(zip_code = region_name) %>% 
  pivot_longer(
    cols = matches("^x\\d{4}_\\d{2}_\\d{2}$"),
    names_to = "date",
    values_to = "zori"
  ) %>%
  mutate(date = str_remove(date, "^x") %>% 
         str_replace_all("_", "-") %>% 
         ymd()) %>% 
  left_join(
    zip,
    by = "zip_code",
    relationship = "many-to-many"
  ) %>% 
  left_join(borough_mapping, by = "county") %>% 
  select(-county_name)

view(zillow_data)
```

### 3. Description

The tidy dataset contains 17516 total observations, covering 149 unique
ZIP codes and 42 unique neighborhoods.

### 4. ZIP codes that were excluded

``` r
missing_zips <- setdiff(zip$zip_code, unique(zori$region_name))

missing_zips
```

    ##   [1] 10464 10474 10475 10499 10550 10704 10705 10803 11202 11224 11239 11241
    ##  [13] 11242 11243 11245 11247 11251 11252 11256 10008 10020 10041 10043 10045
    ##  [25] 10047 10048 10055 10072 10080 10081 10082 10087 10101 10102 10103 10104
    ##  [37] 10105 10106 10107 10108 10109 10110 10111 10112 10113 10114 10115 10116
    ##  [49] 10117 10118 10119 10120 10121 10122 10123 10124 10125 10126 10129 10130
    ##  [61] 10131 10132 10133 10138 10149 10150 10151 10152 10153 10154 10155 10156
    ##  [73] 10157 10158 10159 10160 10161 10163 10164 10165 10166 10167 10168 10169
    ##  [85] 10170 10171 10172 10173 10174 10175 10176 10177 10178 10179 10185 10197
    ##  [97] 10199 10213 10242 10249 10256 10259 10260 10261 10265 10268 10269 10270
    ## [109] 10271 10272 10273 10274 10275 10276 10277 10278 10279 10281 10285 10286
    ## [121] 10292 11001 11004 11005 11040 11096 11351 11352 11359 11362 11363 11371
    ## [133] 11380 11381 11386 11405 11411 11412 11413 11414 11416 11417 11419 11420
    ## [145] 11421 11422 11423 11424 11425 11427 11428 11429 11430 11431 11433 11436
    ## [157] 11439 11451 11499 11559 11580 11690 11694 11695 11697 10302 10307 10309
    ## [169] 10310 10311 10313

- According to the introduction of the zori dataset, ZORI is the Zillow
  Observed Rent Index, and its characteristics are:

  - Only cover residential areas with an active rental market.

  - The calculation is based on the listed rent data and only takes the
    middle rent range from the 35th to the 65th percentile.

  - A sufficient number of listing samples are needed to generate stable
    indicators.

- Therefore, the main reasons for some ZIP files being missing are as
  follows:

  - ZIP for non-residential use

  - Insufficient sample size/No listing

  - Atypical housing market

  - Data quality considerations

For example, according to online information, the ZIP code 10045 is
exclusive to the Federal Reserve Bank building: ![](WechatIMG90.png)

The ZIP code 11430 is JFK airport. There is basically no housing here.

![](WechatIMG91.jpg)

The zip code 10199 is for USPS facilities:

![](WechatIMG92.jpg)

### 5. Fluctuating rental prices

``` r
price_change <- zillow_data %>%
  filter(date %in% c(ymd("2020-01-31"), ymd("2021-01-31"))) %>%
  select(zip_code, date, zori, borough, neighborhood) %>%
  group_by(zip_code, date, borough, neighborhood) %>%
  summarize(zori = mean(zori, na.rm = TRUE), .groups = "drop") %>%
  pivot_wider(
    names_from = date,
    values_from = zori
  ) %>%
  # Calculate the decline in rent (use backticks for column names with special characters)
  mutate(drop = `2020-01-31` - `2021-01-31`) %>%
  # Sort by the largest to the smallest decline
  arrange(desc(drop)) 
  
head(price_change, 10)
```

    ## # A tibble: 10 × 6
    ##    zip_code borough   neighborhood               `2020-01-31` `2021-01-31`  drop
    ##       <dbl> <chr>     <chr>                             <dbl>        <dbl> <dbl>
    ##  1    10007 Manhattan Lower Manhattan                   6334.        5422.  913.
    ##  2    10069 Manhattan <NA>                              4623.        3875.  748.
    ##  3    10009 Manhattan Lower East Side                   3406.        2692.  714.
    ##  4    10016 Manhattan Gramercy Park and Murray …        3731.        3019.  712.
    ##  5    10001 Manhattan Chelsea and Clinton               4108.        3398.  710.
    ##  6    10002 Manhattan Lower East Side                   3645.        2935.  710.
    ##  7    10004 Manhattan Lower Manhattan                   3150.        2444.  706.
    ##  8    10038 Manhattan Lower Manhattan                   3573.        2876.  698.
    ##  9    10012 Manhattan Greenwich Village and Soho        3629.        2942.  686.
    ## 10    10010 Manhattan Gramercy Park and Murray …        3697.        3012.  685.

- From January 2020 to January 2021, all the top ten boroughs with the
  largest rent declines were in **Manhattan**, indicating that the core
  area of Manhattan was the most severely affected during the pandemic.
  It mainly focuses on several neighborhoods: Lower Manhattan (10007,
  10004, 10038), Lower East Side (10009, 10002), Gramercy Park and
  Murray Hill (10016) 10010), Chelsea and Clinton (10001), Greenwich
  Village and Soho (10012).

- Its decline was between 680 and 910 US dollars, with the maximum drop
  being in 10007, a decrease of approximately 913 dollars.

- The main reason for the impact on Manhattan might be the remote
  working during the pandemic, which led to a sharp decline in rental
  demand in business districts and an oversupply in the high-end rental
  market.
